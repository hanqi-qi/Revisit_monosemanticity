{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c265562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import time\n",
    "from transformers.integrations import WandbCallback\n",
    "from llama_hook_test import Llama7BHelper\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "import logging\n",
    "import pathlib\n",
    "import typing\n",
    "\n",
    "import json\n",
    "import gc\n",
    "from typing import Dict, Optional, Sequence\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import transformers\n",
    "from transformers import Trainer, BitsAndBytesConfig\n",
    "import torch\n",
    "from models.model_generate import model_generate_once\n",
    "from utils import reward_utils\n",
    "from lora_attribute.train_val_datasets import AlpacaSupervisedDataset\n",
    "from test_examples import load_queries\n",
    "import pickle\n",
    "import wandb\n",
    "#load model utils\n",
    "from models.model_utils import load_local_policy\n",
    "from CustomerTrainer import CustomTrainer\n",
    "from lora_attribute.args import (\n",
    "    ModelArguments,\n",
    "    TrainingArguments, \n",
    "    LoraArguments, \n",
    "    LorraArguments,\n",
    ")\n",
    "from transformers.utils import logging\n",
    "from models.llama_hook import get_feas_by_hook\n",
    "logging.set_verbosity(transformers.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55dad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    cache_dir=training_args.cache_dir,\n",
    "    device_map=device_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_hooks = get_feas_by_hook(model,target_acts=[\"mlp.up_proj\"],target_layers=[31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class attri_cls(nn.Module):\n",
    "    self.attri_vec = nn.Parameter()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
